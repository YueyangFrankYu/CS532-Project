{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "# from pyspark.sql.functions import when\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StringIndexer, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "spark= SparkSession.builder.getOrCreate()\n",
    "\n",
    "path = './train_final'\n",
    "paths = [path+'/'+str(i)+'.csv' for i in range(23)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleanup\n",
    "df = spark.read.csv(paths,header=True)\n",
    "df = df.dropna()\n",
    "(trainData, testData) = df.randomSplit([0.7, 0.3], seed = 100)\n",
    "# df = df.withColumn('Category',when(df.Category == 'Positive',1.).when(df.Category == 'Neutral',0.).when(df.Category == 'Negative',-1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline \n",
    "tokenizer = Tokenizer(inputCol=\"tokens\", outputCol=\"words\")\n",
    "countVectors = CountVectorizer(inputCol=\"words\", outputCol=\"cv\", vocabSize=30000, minDF=5)\n",
    "idf = IDF(inputCol='cv',outputCol='features',minDocFreq=5)\n",
    "label = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "lr = LogisticRegression()\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "pipeline = Pipeline(stages=[label, tokenizer, countVectors, idf, lr])\n",
    "# pipeline = Pipeline(stages=[tokenizer, countVectors, idf, label_stringIdx,nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search w/ cv \n",
    "%time\n",
    "paramGrid = (ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 0.2,]).addGrid(lr.maxIter, [20, 50, 100]).addGrid(lr.elasticNetParam, [0., 0.5, 1.0]).build())\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(trainData)\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print the results\n",
    "print(\"CV Accuracy:\", accuracy)\n",
    "print(\"CV Precision:\", precision)\n",
    "print(\"CV Recall:\", recall)\n",
    "\n",
    "bestModel = cvModel.bestModel\n",
    "cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with selected params\n",
    "# lr = LogisticRegression(regParam = ' ', maxIter= ' ', elasticNetParam = ' ')\n",
    "# pipeline = Pipeline(stages=[label, tokenizer, countVectors, idf, lr])\n",
    "\n",
    "lrModel = pipeline.fit(trainData)\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# lrModel.write().overwrite().save(\"/Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
